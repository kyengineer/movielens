---
title: "Movie Lens"
author: "John Downey"
date: "1/9/2020"
output:
  word_document: default
  pdf_document: default
---

```{r}
knitr::opts_chunk$set(echo = TRUE)


```



**1.	Introduction**

The MovieLens dataset contains ratings for 10667 movies reviewed by 69878 users. There were broken down to 19 different genres or up to 797 where many movies had more than one genre.

-Objective

The objective of this assignment is to create a Movie Recommendation System based on MovieLens data set provided.  Code is provided that will create and “edx” data set for training and a “validation set for testing.  The edx set consisted of 9,000,055 observations and the validation set 999,999.


The database hads six(6) columns with the following labels.  


* userId: Unique identification number given to each user. It is a Factor variable.
* movieId: Unique movie identification number
* rating: Movie Rating
* timestamp: Date-Time when movie was reviewed
* title: Movie title and Movie Year
* genres: Motion-picture category associated to the film. it is Factor variable.


- Measurement of Success
The Residual Mean Squared Error less than 0.8775l will indicate success.

The structure used is listed below"

1.	Create a training set (edx) and test set from the code provided. 
2.	Perform analysis on the test set
3.	Create models
    There are several motels used.  The initial model used used the n described in the book.
4.	Test the Models
5.  Conclusion


The key measurement is RMSE residual means loss means. This is the square root of the sum of the squares of differences between actual and predicted ratings divided by the total number of observations.  The model prediction is less than 0.8775.

It should be noted several .R files were created for this project for ease of editin and debugging. Once one section was developed I did not want to go back recreate tje dataframe.


**Executive Summary**
Using the MovieLens database a dateframe for R was created with the ratings of over 10,000 movies by over 70,000 users.  This resulted in over 10,000,000 observations. 

Using Penalized Least Squares model was optimized 

Using liner

**Methods**

2. Training Set Creation.

2.1 Initial Data Sets.

Code was provided to generate the training and validation data sets. This code is included in the ".R" file but not indluded in this report. This secton of code a dataframe call edx.Rdm is the training set and validation.Rdm is the validation set. To ease developemnt the data sets edx.R and validation.R are stored. 


2.2  Data Storage

The provide code was used to create the edx and validaion sets. The code below save the datframes 


```{}
# Save training and testing data s
save(edx, file="edx.Rda")
save(validation, file="validation.Rda")

```

This section creates the test data set and training data set from the edx set.
```{r echo=FALSE}
library(dplyr)
library(ggplot2)
library(tidyverse)
```

```{r}
load("edx.Rda")
load("validation.Rda")
```

A review of the first six(6) rows of the edx and valication dataframe indicates saving and loading the dataframe worked.  When running this file the "#" can be removed to 

edX Dataframe
```{r}
#head(edx)

```

As can be seen from the code below the edx dataframe is 10,000,000 obserbations

```{r}
dim(edx)
```
This is the section of code used to create the training sets and the test sets.  This code is not run because it crashed R.  When ran as "R" cost the creation of the test set works.  For simplicity the code is listed.  
```{}
#Create Train Sets and Test Sets
set.seed(755)
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.2, list = FALSE)
train_set <- edx[-test_index,]
test_set <- edx[test_index,]

test_set <- test_set %>%
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")
#Save the training set and test set so they will not need to be recalculated.
save(train_set, file="train_set.Rda")
save(test_set, file="test_set.Rda")

```

The code below shows there are 19 different genres and 6 movies with no genres.  Movies can have more than one genre.  
```{r}
#Names oF Genres
genre_list <-  edx %>% separate_rows(genres, sep = "\\|") %>%
  group_by(genres) %>%
  summarize(count = n()) %>%
  arrange(desc(count))
```

```{r}
genre_list

```

```{r}
#Add seperate column for each genre
#Create a new Dataframe adding a seperate column for each genre
edx_genre_col <- edx %>% mutate(Drama=str_detect(genres, "Drama")) %>% 
  mutate(Comedy=str_detect(genres, "Comedy")) %>%
  mutate(Action=str_detect(genres, "Action")) %>%
  mutate(Thriller=str_detect(genres, "Thriller")) %>%
  mutate(Adventure=str_detect(genres, "Adventure")) %>%
  mutate(Romance=str_detect(genres, "Romance")) %>%
  mutate(Sci_fi=str_detect(genres, "Sci-Fi")) %>%
  mutate(Crime=str_detect(genres, "Crime")) %>%
  mutate(Fantasy=str_detect(genres, "Fantasy")) %>%
  mutate(Children=str_detect(genres, "Children")) %>%
  mutate(Horror=str_detect(genres, "Horror")) %>%
  mutate(Mystery=str_detect(genres, "Mystery")) %>%
  mutate(War =str_detect(genres, "War")) %>%
  mutate(Animation=str_detect(genres, "Animation")) %>%
  mutate(Musical=str_detect(genres, "Musical")) %>%
  mutate(Western=str_detect(genres, "Western")) %>%
  mutate(Film_Noir=str_detect(genres, "Film-Noir")) %>%
  mutate(Documentary=str_detect(genres, "Documentary")) %>%
  mutate(IMAX=str_detect(genres, "IMAX")) %>%
  mutate(None=str_detect(genres, ""))


```
Because the edx file are so large using any caret package crashes the pc becasue of the length of time it takes to perform the analysis, therefore smaller datasets need to be created.  

```{r}
#Save the dataframe with the genres broken out.
save(edx_genre_col, file = "edx_genre_col.Rda")
#remove all column accept movie title
edx_genre_logical <-  subset(edx_genre_col, select= -c(userId, movieId, timestamp, title, genres))
```

```{r}
#Create a 10,000 observation dataframe for testing
edx_genre_logical_10 <- edx_genre_logical[sample(nrow(edx_genre_logical), 10000),]
save(edx_genre_logical_10, file = "edx_genre_logical_10.Rda")
dim(edx_genre_logical_10)

#Create a 1,000 observation dataframe for testing
edx_genre_logical_1 <- edx_genre_logical[sample(nrow(edx_genre_logical), 1000),]
save(edx_genre_logical_10, file = "edx_genre_logical_1.Rda")
dim(edx_genre_logical_10)
```



**Analysis**
This section is where the we analyze the data.


First we need to know the number of unique users, movies and genres that are in the dataset.
```{r}
# Summary of the number of users and movies.  
edx %>%
  summarize(n_users = n_distinct(userId),
            n_movies = n_distinct(movieId),
            n_genres = n_distinct(genres))

```
This section show the mean rating 3.5 and the Median rating is 4.0  We can see over half the movies are good. 
```{r}

summary(edx$rating)
```

The plots below shows over half the movies are good.  
```{r}
edx %>% ggplot(aes(rating)) +
  geom_histogram(bins = 25, color = "black") +
  labs(title = "Distribution of ratings",
       subtitle = "by # of Ratings",
       x = "Rating",
       y = "Frequency")
```

```{r}
#Graph of percentage each rating recieved
x <- round(table(edx$rating)/10000000*100,1)

x1 <- as.data.frame(x)

ggplot(data = x1, aes(Var1, Freq)) +
  geom_bar( stat = "identity") +
  labs(title = "Distribution of ratings",
     subtitle = "by # of Ratings",
     x = "Rating",
     y = "Percent")

```

```{r}
# This shows the movies that have move than 3000 reviews

movieId_count <- edx %>% count(userId) %>% arrange(desc(n))
print(filter(movieId_count, n > 3000))

```
Top Movies with more 20,000 users rating the movie.
```{r}

movie_title <- edx %>% group_by(title) %>% count() %>% arrange(desc(n))  
filter(movie_title, n > 20000)
```
Historgram of number of movie ratings per movie.

We can see only 1907 out of 10067 were rated by more than 1,000 people.

```{r}
dim(filter(movie_title, n > 1000))
```

```{r}

movie_Id <- edx %>% group_by(movieId) %>% count() %>% arrange(desc(n))

movie_Id %>% ggplot(aes(n)) + 
  geom_histogram(bins = 25, color = "black") +
  labs(title = "Distribution of Number of Rating per Movie",
       subtitle = "Distribution of Titles",
       x = "Number of Reviews per Title",
       y = "Movie Number")

```

Genre Analysis

```{r}

#This section provides the average rating and SD per genres.  
#Group by genres
genres_grouped <- group_by(edx, genres)

genre_mean <- summarise(genres_grouped, Avg_genre = mean(rating), sd_genre = sd(rating))
head(genre_mean)
```
Analysis of ratings based on genre
In this section the we can see genre can indicate the movie rating.   There were 43 genres with ratings of 4 or greater.  From the data below genres can be a good indicator of a good movie.
```{r}
count(filter(genre_mean, Avg_genre >= 3 & Avg_genre < 4))
```

```{r}

count(filter(genre_mean, Avg_genre >= 4))
```



```{r}
#Plot to show distrubution  of the averge ratings per genre

genre_mean %>% ggplot(aes(Avg_genre)) +
  geom_histogram(bins = 100, color = "black") +
  labs(title = "Distribution of Average Ratings per genre",
       subtitle = "",
       x = "Rating",
       y = "Genre")

```

```{r}
#This plot shows the distrubuion of the SD of the rating per genres.  
genre_mean %>% ggplot(aes(sd_genre)) +
  geom_histogram(bins = 25, color = "black") +
  labs(title = "Distribution of  Standard Deviation ratings",
       subtitle = "None",
       x = "Standard Deviation",
       y = "Genre")

```

```{r}

#Genarate a plot showing the 
genres_list <- as.data.frame(table(edx$genres))

head(genres_list)

genres_list %>% ggplot(aes(Freq)) +
  geom_histogram(bins = 20, color = "black") +
  labs(title = "Distribution of genres",
       subtitle = "by # of Ratings",
       x = "Genre",
       y = "Frequency")
```


3.	Development of recommendation model

The code to generate the training sets and the test sets were provided with the problem.  Therefore, it was not required to create test and validation sets.

An exploratory test I tried to use CARET LM function and and randomForest function to test the data set Error: cannot allocate vector of size 67.1 Gb. 
The lm function was also tested using genre factors only.  This required 

My first step was to try to attempt to run the code provided to create the two data sets. After running the code, the data was saved as a Rda file. An attempt to tried running the lm machine learning algorithm but I received an error message.  In order to avoid the error message I took a subset of the dataset.  
The success of the model is measured using RMSE.  The formula for is located in ML_3.R line 23


Load test and training dataframes from previously 

```{r}
load("test_set.Rda")
load("train_set.Rda")


```

We can see the average for movie is 3.51
```{r}
#Test to ensure table command exracted all the ratings

mu_hat <- mean(train_set$rating)
mu_hat

RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
}
```
We will first use the average rating and compare it to the test set.  We the RMSE is greater than the required RMSE for maximum points.
```{r}

naive_rmse <- RMSE(test_set$rating, mu_hat)
naive_rmse

rmse_results <- data_frame(method = "Just the Average", RMSE = naive_rmse)
rmse_results

```


Next we add take into account the individual movie ID
```{r}
#Mean Ration Calcuation
mu <- mean(train_set$rating)
# Add inidvidules movie ID to Model pg 650
movie_avgs <- edx %>%
  group_by(movieId) %>%
  summarize(b_i = mean(rating - mu_hat))
```
From the histogram we can see each movie has b value.
```{r}
# pg 650
movie_avgs %>% qplot(b_i, geom ="histogram", bins = 10, data = ., color = I("black"))

# pg 651
```

3.1.	Model: Average Rating 

This is the simplest model.  This model is an average of all movies.  This is not a good model because all movies are rated the same. (ML_3, l 30)

```{r}
predicted_ratings <- mu + train_set %>%
  left_join(movie_avgs, by='movieId') %>%
  .$b_i

model_1_rmse <- RMSE(predicted_ratings, test_set$rating)

model_1_rmse

rmse_results <- bind_rows(rmse_results, 
                          data_frame(method="Movie Effect Model",
                                     RMSE = model_1_rmse))
rmse_results %>% knitr::kable()
```

Histogram of the userId factor.  We can see the user does effect the influence the outcome. 

```{r}

#User ID Effect Pg 650
#
test_set %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating)) %>%
  filter(n()>=100) %>%
  ggplot(aes(b_u)) +
  geom_histogram(bins = 30, color = "black")
```

3.2 Add movie ID

```{r}
#pg 652
user_avgs <- train_set %>%
  left_join(movie_avgs, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = mean(rating - mu - b_i))

predicted_ratings <- test_set %>%
  left_join(movie_avgs, by='movieId') %>%
  left_join(user_avgs, by='userId') %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

model_2_rmse <- RMSE(predicted_ratings, validation$rating)
model_2_rmse

rmse_results <- bind_rows(rmse_results, 
                          data_frame(method="Movie + Users Effect Model",
                                     RMSE = model_2_rmse))
rmse_results %>% knitr::kable()
```

Finally we add regularization 


```{r}

#pg 659 
#Movie effect and User Effect with Regualization using the test_set data
lambdas <- seq(0, 10, 0.25)

rmses <- sapply(lambdas, function(l){
  mu <- mean(train_set$rating)
  b_i <-  train_set %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  b_u <- train_set %>%
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  predicted_ratings <-
    test_set %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  return(RMSE(predicted_ratings, test_set$rating))
})
```

Several test were conducted using genres to predict the ratings.  In order to run the code, only 10,000 obsevation could be used.  The 19 genres were converted to 19 dummy variables.  Random forests was used to model the data.

```{r}
#Using a 10,000 
#train_10 <-  train(rating ~ ., data = edx_genre_logical_10, method="rf")
#train_10
#predict_10 <- predict(train_10, edx_genre_logical_1, type = "raw")
```

This section we are using genre to model ratings.  

```{}
#Using a 10,000 
train_10 <-  train(rating ~ ., data = edx_genre_logical_10, method="rf")
train_10
predict_10 <- predict(train_10, edx_genre_logical_1, type = "raw")
```

Below is the RMSE for using genre only.  Genre is the variable independent of the userId and movie name.  This can be used to predict ratings of new movies. 

The RMSE was 1.017262.  This code does select not to run because of the excessively large coumpution time.  

```{}
RMSE(predict_10, edx_genre_logical_1$rating)

```
Other model from the caret package were attempted but crashed the PC or never stopped running.  A example of r code to test several different models is listed below. 

```{}
models <- c("lda",  "naive_bayes",  "svmLinear", 
            "gamboost",  "gamLoess", "qda", 
            "knn", "kknn", "loclda", "gam",
            "rf", "ranger",  "wsrf", "Rborist", 
            "avNNet", "mlp", "monmlp",
            "adaboost", "gbm",
            "svmRadial", "svmRadialCost", "svmRadialSigma")

models <- c("lm", "knn", "kknn", "brnn", "randomGLM")
models <- c( "lm", "knn")
models <- c("rf", "lm")

str(models)

fits1 <- sapply(models, function(model){
  print(model)
  train(rating ~., method = models, data = edx_genre_logical_10)
  predict(models, data = edx_genre_logical_10)
  return(RMSE(predict_10, edx_genre_logical_10$rating))
})
```

**Results**

This sections shows the results of the above analysis.  

Comparison of RMSES to the Grading Rubric

```{r}
min(rmses)
min(rmses) <= 0.87750

```
Plot showing lamba tuning parameter vs. RMSE
```{r}
qplot(lambdas,rmses)
```


**Conclusion**

Based on the RMSE results above the model was rerun using edx as the training set and validation as the test set.  the minimum RSME was 0.8649587.  This is 0.000587 greater the RMSE value that grades with the maximum points. 

Use a genre only model where 20 dummy variables were created from genres column. The model was run with only 5000 obsevations.  This models RMSE was 1.01.  

**Forward Looking**

To use advanced modeling package such as caret requires a much more powerful computer.

```{r}
#Run the same function using the edx and validation datasets lamba calculated above.
rmses_v <- sapply(lambdas, function(l){
  mu <- mean(edx$rating)
  b_i <-  edx %>%
    group_by(movieId) %>%
    summarize(b_i = sum(rating - mu)/(n()+l))
  b_u <- edx %>%
    left_join(b_i, by="movieId") %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - b_i - mu)/(n()+l))
  predicted_ratings <-
    validation %>%
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  return(RMSE(predicted_ratings, validation$rating))
})

```
This is the plot that shows the minimum lamba.
```{r}
qplot(lambdas,rmses_v)
```

```{r}

lambda <- lambdas[which.min(rmses_v)]
lambda 
min(rmses_v)

min(rmses_v) <= 0.8649
min(rmses_v) <= 0.86499
```

